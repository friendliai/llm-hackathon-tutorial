{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling with Chat API\n",
    "\n",
    "본 튜토리얼을 통해 Friendli Serverless Endpoints의 Chat 모델을 활용하여 동적으로 함수 호출에 필요한 인자를 생성하고, 이를 활용하여 함수를 호출하여 정보를 얻는 방법에 대해서 알아 봅시다.\n",
    "\n",
    "Function calling이란 모델에게 사전에 정의한 함수의 정보(e.g., 함수 이름, 함수의 인자들, 함수의 설명)와 함께 질문을 했을 때, 그 질문에 알맞는 함수 호출을 할 수 있도록 모델이 함수의 인자 값을 생성해주는 기능을 말합니다. Function calling 기능은 다음과 같은 단계를 거쳐 활용이 가능합니다.\n",
    "\n",
    "1. 함수의 인자를 생성\n",
    "2. 생성된 함수 인자를 활용하여 함수 호출\n",
    "\n",
    "함수 호출 결과는 이후 새로운 모델 답변을 생성할 때 입력으로 활용을 할 수 있습니다. 그러면 함수 호출을 통해 동적으로 생성한 정보를 답변 생성에 반영할 수 있습니다. 이런 점에서 function calling은 Retrieval Augmented Generation (RAG)에 활용 가능한 기법이라고 볼 수 있습니다. 즉, 질문의 의도가 반영된 동적인 함수 호출을 통해 정보를 가져오는 부분이 벡터 데이터베이스에서 질문에 해당하는 정보를 가져오는 부분과 비슷하다고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Client\n",
    "\n",
    "Friendli Serverless Endpoints는 OpenAI와 동일한 스키마의 Chat API를 제공합니다. Function calling 기능 역시 OpenAI Chat API와 동일한 옵션으로 사용이 가능합니다.\n",
    "튜토리얼 진행을 위해 OpenAI Python 클라이언트를 설치합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Function\n",
    "\n",
    "호출하고 싶은 함수를 정의합니다. 이 예제에서는 미리 정의된 입력(=지역)에 대해 정해진 결과(=기온)를 반환하는 dummy 함수를 정의하였습니다. 물론 실제 응용 사례에서는 날씨 서버에서 정보를 가져오는 함수를 정의해서 사용을 해야겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"seoul\" in location.lower():\n",
    "        return {\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": unit}\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
    "    elif \"paris\" in location.lower():\n",
    "        return {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit}\n",
    "    else:\n",
    "        return {\"location\": location, \"temperature\": \"unknown\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Function Calling Request\n",
    "\n",
    "이제 Chat API를 통해 함수 호출에 사용될 인자를 생성해봅시다.\n",
    "\n",
    "우선 Friendli Serverless Endpoints에 API call 시 사용할 **Personal Access Token**을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "friendli_token = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자가 오늘과 같은 날씨에 어떤 옷을 입어야 하는지 질문을 한다고 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_from_user = \"I live in Seoul. What should I wear for today's weather?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI client를 사용해서 요청을 보냅니다.\n",
    "\n",
    "- 이 때 사용자의 질문은 `messages` 옵션에 `user` role의 `content`로 들어갑니다.\n",
    "- 위에서 정의했던 `get_current_weather` 함수의 정보는 `tools` 옵션에 들어갑니다. 이 때 `parameters`에는 위에서 정의했던 함수의 인자 정보가 [JSON Schema](https://json-schema.org/) 형식으로 제공해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id=None, choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_001', function=None, type=None, arguments='{\"location\":\"Seoul\",\"unit\":\"celsius\"}', name='get_current_weather')]))], created=1716465005, model=None, object=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=22, prompt_tokens=121, total_tokens=143))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"https://inference.friendli.ai/v1\", api_key=friendli_token)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question_from_user,\n",
    "    },\n",
    "]\n",
    "\n",
    "tools=[\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",  # 위에서 정의한 함수의 이름\n",
    "            \"description\": \"Get the current weather information in a given location.\",  # 함수에 대한 설명\n",
    "            \"parameters\": {  # JSON Schema로 정의한 함수의 인자 정보\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of current location e.g., Seoul\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The unit of temperature degree.\",\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "chat = client.chat.completions.create(\n",
    "    model=\"meta-llama-3-8b-instruct\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 답변의 `arguments` 필드에 포함된 함수의 인자 값을 위에서 정의된 함수에 그대로 unpacking 하여 호출하면 사용자의 질문의 의도가 반영된 함수 호출 결과를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Seoul', 'temperature': '10', 'unit': 'celsius'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "func_kwargs = json.loads(chat.choices[0].message.tool_calls[0].arguments)\n",
    "\n",
    "weather_info = get_current_weather(**func_kwargs)\n",
    "print(weather_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "client",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
